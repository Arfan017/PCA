# -*- coding: utf-8 -*-
"""PCA5_modif.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1K8iPeW3hcV_uEyuLRGK9j_BrkOL4YJiH
"""

# from google.colab import drive
# drive.mount('/content/drive')

import os
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
from keras.models import Sequential
from keras.layers import Dense, Input
from keras.utils import to_categorical
from keras.optimizers import RMSprop
# !pip install -U --pre efficientnet
from efficientnet.tfkeras import EfficientNetB1
from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization

# Muat dataset Anda
# Tentukan direktori dataset Anda
num_classes = 2
dataset_dir = "F:/DeepLearning/PCA/Dataset"

# Inisialisasi daftar gambar sebagai daftar kosong
moi_images = []
non_moi_images = []

# Iterasi melalui direktori dataset
for root, dirs, files in os.walk(dataset_dir):
    for file in files:
        if file.endswith(".jpg") or file.endswith(".png"):
            # Tentukan label gambar (0 untuk moi, 1 untuk non moi)
            label = 0 if "moi" in root else 1

            try:
                # Muat gambar dan ubah ukurannya menjadi 32x32 piksel
                image = Image.open(os.path.join(root, file))
                image = image.resize((32, 32))
                image = np.array(image)

                # Tambahkan gambar ke daftar yang sesuai
                if label == 0:
                    moi_images.append(image)
                else:
                    non_moi_images.append(image)
            except Exception as e:
                print(f"Error loading image: {file}")

# Cetak jumlah gambar dalam setiap daftar
print(f"Jumlah gambar moi: {len(moi_images)}")
print(f"Jumlah gambar non moi: {len(non_moi_images)}")

# Konversi daftar gambar menjadi array NumPy
x_train = np.array(moi_images + non_moi_images)

# Buat label untuk setiap gambar
y_train = np.array([0] * len(moi_images) + [1] * len(non_moi_images))

# Bagi dataset menjadi data pelatihan dan pengujian
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.2, random_state=42)

print('Traning data shape:', x_train.shape)
print('Testing data shape:', x_test.shape)

y_train.shape, y_test.shape

import numpy as np

classes = np.unique(y_train)
nClasses = len(classes)

print('Total number of outputs : ', nClasses)
print('Output classes : ', classes)

label_dict = {
 0: 'moi',
 1: 'non_moi',
}

import matplotlib.pyplot as plt

plt.figure(figsize=[5,5])

# Display the first image in training data
index = 0
plt.subplot(121)
curr_img = np.reshape(x_train[index], (32,32,3))
plt.imshow(curr_img)
curr_label = str(label_dict[y_train[0]])
print(plt.title('(Label: {})'.format(curr_label)))

# Display the first image in testing data
index = 0
plt.subplot(122)
curr_img = np.reshape(x_test[index],(32,32,3))
plt.imshow(curr_img)
curr_label = str(label_dict[y_test[0]])
print(plt.title('(Label: {})'.format(curr_label)))

np.min(x_train), np.max(x_train)

x_train_normalized = x_train/np.max(x_train)

np.min(x_train_normalized), np.max(x_train_normalized)

x_train_normalized.shape

from functools import reduce

n_cols = reduce((lambda x, y: x * y), x_train_normalized.shape[1:])
print(n_cols)

x_train_flat = x_train_normalized.reshape(-1, n_cols)
x_train_flat.shape

feat_cols = ['pixel{}'.format(str(i)) for i in range(x_train_flat.shape[1])]

import pandas as pd

df_cifar = pd.DataFrame(x_train_flat,columns=feat_cols)

df_cifar['label'] = y_train
df_cifar.shape

df_cifar.head()

from sklearn.decomposition import PCA

pca_cifar = PCA(n_components=3)
principalComponents_cifar = pca_cifar.fit_transform(df_cifar.iloc[:,:-1])


principal_cifar_Df = pd.DataFrame(data = principalComponents_cifar
             , columns = ['principal component 1', 'principal component 2', 'principal component 3'])
principal_cifar_Df['y'] = y_train

principal_cifar_Df.head()

print('Explained variation per principal component: {}'.format(pca_cifar.explained_variance_ratio_))

import seaborn as sns
plt.figure(figsize=(16,10))
sns.scatterplot(
    x="principal component 1", y="principal component 2",
    hue="y",
    palette=sns.color_palette("hls", 2),
    data=principal_cifar_Df,
    legend="full",
    alpha=0.3
)

plt.figure(figsize=(16,10))
sns.scatterplot(
    x='principal component 2', y='principal component 3',
    hue="y",
    palette=sns.color_palette('hls', 2),
    data=principal_cifar_Df,
    legend='full',
    alpha=0.3
)

x_test_normalized = x_test/np.max(x_test)

x_test_flat = x_test_normalized.reshape(-1, n_cols)
x_test_flat.shape

pca = PCA(0.9)

pca.fit(x_train_flat)

pca.n_components_

train_img_pca = pca.transform(x_train_flat)
test_img_pca = pca.transform(x_test_flat)

from keras.models import Sequential
from keras.layers import Dense
from keras.optimizers import RMSprop

y_train = to_categorical(y_train)
y_test = to_categorical(y_test)

batch_size = 128
num_classes = nClasses
num_components = pca.n_components_
epochs = 20

model = Sequential()
model.add(Input(shape=(num_components,)))
model.add(Dense(1024, activation='relu'))
model.add(Dense(512, activation='relu'))
model.add(Dense(256, activation='relu'))
model.add(Dense(num_classes, activation='softmax'))

model.summary()

model.compile(loss='categorical_crossentropy',
              optimizer=RMSprop(),
              metrics=['accuracy'])

history = model.fit(train_img_pca, y_train, batch_size = batch_size ,epochs = epochs, verbose=1,
                    validation_data=(test_img_pca, y_test))

model.evaluate(test_img_pca, y_test)

plt.plot(history.history['accuracy'], label='acc', color='red')
plt.plot(history.history['val_accuracy'], label='val_acc', color='green')
plt.legend()

from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
from sklearn.metrics import ConfusionMatrixDisplay

y_pred = model.predict(test_img_pca).argmax(axis=1)

conf_matrix = confusion_matrix(np.argmax(y_test, axis=1), y_pred)
display = ConfusionMatrixDisplay(confusion_matrix = conf_matrix, display_labels = ['moi', 'non_moi'])

display.plot()
plt.show()

report = classification_report(np.argmax(y_test, axis=1), y_pred, target_names=['moi', 'non_moi'])
print(report)

# # Muat dan proses gambar baru
# new_image = Image.open("/content/drive/MyDrive/Dataset/rajaampat/rajaampat (97).jpg")  # Ganti dengan kode untuk memuat dan memproses gambar baru

# # Ubah ukuran gambar baru menjadi 32x32 piksel
# new_image = new_image.resize((32, 32))

# # Konversi gambar baru menjadi array NumPy
# new_image = np.array(new_image)

# # Ratakan gambar baru
# new_image_flat = new_image.reshape(1, -1)

# # Terapkan PCA
# new_image_pca = pca.transform(new_image_flat)

# # Prediksi label kelas
# prediction = model.predict(new_image_pca)

# labels = '''moi non_moi'''.split()

# # Dapatkan label kelas yang diprediksi
# predicted_class = np.argmax(prediction)
# predicted_label = labels[np.argmax(prediction)]

# # Cetak label kelas yang diprediksi
# print("Label kelas yang diprediksi:", predicted_class, "\nlabel:", predicted_label)

# Simpan model
# model.save('PCA_model.h5')

def predict_image(image_path):
    # Muat dan proses gambar baru
    new_image = Image.open(image_path)  # Ganti dengan kode untuk memuat dan memproses gambar baru

    # Ubah ukuran gambar baru menjadi 32x32 piksel
    new_image = new_image.resize((32, 32))

    # Konversi gambar baru menjadi array NumPy
    new_image = np.array(new_image)
    print( "Image Array: ",new_image)

    # Ratakan gambar baru
    new_image_flat = new_image.reshape(1, -1)
    print( "Image Falt: ",new_image)

    # Terapkan PCA
    new_image_pca = pca.transform(new_image_flat)
    print( "Image PCA: ",new_image)
    
    # Prediksi label kelas
    prediction = model.predict(new_image_pca)
    print( "Image Predict: ",new_image)

    labels = '''moi non_moi'''.split()

    # Dapatkan label kelas yang diprediksi
    # predicted_class = np.argmax(prediction)
    predicted_label = labels[np.argmax(prediction)]
    return new_image, predicted_label